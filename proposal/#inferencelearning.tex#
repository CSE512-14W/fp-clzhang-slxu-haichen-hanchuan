

\subsubsection{Maximum a Posteriori Inference} 

The goal of inference is to
find the predictions $z,\mathbf{y}$ which yield the greatest
probability, \ie, \[z^*,\mathbf{y}^* = \arg\max_{z,\mathbf{y}} p(Z=z,
\mathbf{Y} = \mathbf{y}|\mathbf{x}; \Theta)\]

This can be viewed as a MAP inference problem. In general, inference in a
graphical model is challenging. Fortunately, the joint factors in our model are
linear, and the event and relation factors are log-linear; we can cast MAP
inference as an integer linear programming (ILP) problem, and then compute an
approximation in polynomial time by means of linear  programming using
randomized rounding, as proposed in~\cite{Yannakakis92}.


We build one ILP problem for every \eec. The variables of the ILP
are $Z$ and $\mathbf{Y}$, which only take values of 0 or 1.
The objective function is the sum of logs of the event and relation
factors $\Phi^Z$ and $\Phi^Y$. The temporal burstiness heuristic  of
$\Phi^{\text{joint}}$ is encoded as a linear inequality constraint $z\geq y_i$;
the one-mention per discourse heuristic of $\Phi^{\text{joint}}$ is encoded as 
the constraint $\sum_{y_i\in \mathbf{y}_d} y_i \leq 1$. In sum, the ILP problem
is encoded as follows:

\[
  \begin{array}{r@{}r@{}r@{}l}
    \text{Max} \quad &{}\log \Phi^Z + \sum_Y \log \Phi^Y \\[\jot]
    \text{s.t.}\qquad 3x_1 &{} + \phantom{12}x_2 &{} + 12x_3 &{} \leq 5 \\
                      x_1 &         &{} +   \phantom{12}x_3 &{} \leq 16 \\
                    15x_1 &{} + \phantom{12}x_2 &           &{} = 14 \\
     \multicolumn{4}{c}{x_j \geq 0, \quad j=1,2,3.}
  \end{array}
\]



\def\gold{^{\mathsf{gold}}}

\subsubsection{Learning}

Our training data consists of $N=500$ labeled \bag\ in the form of
$\{(R_i,R\gold_i)\mid_{i=1}^N\}$. Each $R$ is the set of all relations
in the \bag\ while $R\gold$ is a manually created subset of $R$
containing relations describing the \eec. $R\gold$ could be empty if
the \eec\ is not good for clustering. For our model, the gold
assignment ${y^r}\gold=1$ if $r\in R\gold$; the gold assignment
$z\gold=1$ if $R\gold$ is not empty.

Given $\{(R_i,R\gold_i)\mid_{i=1}^N\}$, learning over similar models is commonly
done via maximum likelihood estimation as follows:

\[
L(\Theta) = \log \prod_i p(Z_i=z\gold_i,\mathbf{Y}_i=\mathbf{y}\gold_i\mid\mathbf{x}_i,\Theta)
\]

For features in relation factors, the partial derivative for the $i$th model is: %dce
\[
\Phi_j(\mathbf{y}\gold_i,\mathbf{x}_i)-E_{p(z_i,\mathbf{y}_i\mid ,\mathbf{x}_i,\Theta)}\Phi_j(\mathbf{y}_i,\mathbf{x}_i)
\]
where $\Phi_j(\mathbf{y}_i, \mathbf{x}_i)=\sum
\phi_j(X,Y,\mathbf{x})$, the sum of values for the $j$th
feature in the $i$th model; and values of $X,Y$ come from the assignment
$\mathbf{y}_i$. For features in event factors, the partial derivative is derived similarly as
\[
\phi_j(z\gold_i,\mathbf{x}_i)-E_{p(z_i,\mathbf{y}_i\mid ,\mathbf{x}_i,\Theta)}\phi_j(z_i,\mathbf{x}_i)
\]

It is unclear how to efficiently compute the expectations in the above formula,
%$E_{p(z_i,\mathbf{y}_i\mid  ,\mathbf{x}_i,\Theta)}\phi_j(z_i,\mathbf{x}_i)$ and $E_{p(z_i,\mathbf{y}_i\mid   ,\mathbf{x_i},\Theta)}\Phi_j(\mathbf{y}_i,\mathbf{x}_i)$:
a brute force approach requires enumerating all assignments of $\mathbf{y}_i$, which is exponentially large with the number of relations. Instead, we
opt to use a more tractable perceptron
learning approach~\cite{collins02,hoffmann2011knowledge}. Instead of computing the expectations, we simply compute $\phi_j(z^*_i,\mathbf{x}_i)$ and
$\Phi_j(\mathbf{y}^*_i,\mathbf{x}_i)$, where $z^*_i,\mathbf{y}^*_i$ is
the assignment with the highest probability, generated by the MAP
inference algorithm using the current weight vector. The weight
updates are the following:
\begin{align}
&\Phi_j(\mathbf{y}\gold_i,\mathbf{x}_i) - \Phi_j(\mathbf{y}^*_i,\mathbf{x}_i)\label{update_relation_variable}\\
&\phi_j(z\gold_i,\mathbf{x}_i) - \phi_j(z^*_i,\mathbf{x}_i)
\end{align}

The updates can be intuitively explained as penalties on errors. In
sum, our learning algorithm consists of iterating the following two steps: (1) infer the most probable assignment given the current weights; (2) update the weights by comparing inferred assignments and the truth
assignment.

%Note that the focus of this paper is to obtain high precision results, we make a simple modification: we penalize the weight more on false positives than on false negatives. For example, when seeing a false positive $1=z^*_i>z\gold_i=0$, we multiply the update value by a rate $\delta>1$; otherwise the rate is $1$. Similar procedure can be applied to Equation \ref{update_relation_variable}.











