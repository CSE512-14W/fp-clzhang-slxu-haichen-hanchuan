Evaluation of the system:

We will have separate evaluations of the two proposed visualization tools we will build for tow different tasks of natural language processing.

Clustering visualization
In order to evaluate the clustering visualization tool, we will compare that to a traditional linguistics  process of doing word clustering, where the participants are required to manually label each word according to different categories on a Microsoft Excel or similar chart software.

Participants: We will gather 10 native speaker participants form undergraduate/graduate CSE students.
Experiment: We will divide them into two groups, Each group will complete two standard linguistic clustering tasks with similar work load and difficulty. One of the group will conduct the task with help of our visualization tool first, the other will do the task without visualization first. Then the tow groups switch task.

Evaluation: Both time consumption and accuracy of the two groups of participants will be evaluated.

2. Tree Parsing

Because of the difficulty of the Tree Parsing tasks, there is actually no reliable way for people to conduct such tree parsing without tedious training. So our evaluation aim to discover how this good this tool can actually turn something almost impossible to reality.

Participants: We will gather 10 native speaker participants form undergraduate/graduate CSE students.
Experiment: participants will complete two standard linguistic parcing tasks with similar work load and difficulty. One of the group will conduct the task with help of our visualization tool first, the other will do the task without visualization first. Then the two groups switch task.

Evaluation: Both time consumption and accuracy of the two groups of participants will be evaluated.